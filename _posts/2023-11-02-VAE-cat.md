---
layout: post
author: √Åkos Strack
tags: [VAE, variational autoencoder, generative model, deep learning, machine learning, TensorFlow]
title:  "Variational autoencoder: Generating and Transforming Cat Faces"
date:   2023-10-02 11:09:34 +0200
---

## Introduction
In this project, I created a variational autoencoder (VAE) capable of generating and transforming cat faces. I built upon a tutorial from the book "Deep Learning with Python, Second Edition" and some enhancements to achieve better results.

## Dataset
To train our VAE, I utilized the "cat-dataset" from Kaggle, a rich collection of cat images. This dataset contained not only cat faces but also images with backgrounds and other elements. To extract cat faces, I made use of bounding boxes and facial annotations. These annotations included the positions of eyes and ears, which served as valuable data for our project.
![Crop faces](/assets/images/cat/crop_cat.png)

## Vanilla VAE Implementation
My journey began with the implementation of a vanilla VAE, closely following the tutorial from the book. However, I quickly encountered limitations, especially in the quality of the generated cat faces. The resulting images were noticeably blurry, leaving room for improvement.
![Vanilla VAE](/assets/images/cat/basic_vae.png)

## Improved VAE Implementation
To overcome the challenges posed by the vanilla VAE, I decided to revamp the encoder part. Instead of using the two layers of CNN as in the original tutorial, I opted for a pre-trained ResNet architecture. This simple yet powerful change had a remarkable impact on the model's performance. The improved VAE not only generated sharper cat faces but also reduced the training time due to the efficiency of the pre-trained ResNet encoder.
![ResNet VAE](/assets/images/cat/resnet_vae.png)

## Transforming Cat Faces
Beyond generating cat faces, I aimed to provide a more interactive experience by enabling transformations of cat faces. To achieve this, I needed additional annotation data. I extended the dataset with new annotations, including cat color, eye position, and eye openness. These annotations served as the basis for calculating transformation vectors in the latent space.

## Transformation Process
Let's dive into the process of transforming cat faces:
1. **Encoding into Latent Space:** I began by encoding cat faces into the latent space, capturing their essential features. This latent representation would be the canvas for applying various transformations.
2. **Calculating Transformation Vectors:** With the annotated data, I computed transformation vectors that represented changes in cat color, eye position, and eye openness. These vectors guided the desired transformations.
3. **Decoding New Latent Points:** Armed with the transformation vectors, I decoded new latent space points, resulting in transformed cat faces.

![Average tabby](/assets/images/cat/average_tabby.png)
<div style="text-align:center"><i>Averaging the latent space points of tabby cats resulted in a tabby cat face.</i></div>

## Results
The heart of this project lies in the results:
- **Improved VAE Output:** I presented side-by-side comparisons of the improved VAE's output with the vanilla VAE. The difference in image quality was striking, with the improved VAE generating sharper cat faces.
- **Transformation Success:** The project's ability to transform cat faces was visually demonstrated with before-and-after images. The VAE effectively handled cat color changes, eye position adjustments, and eye openness variations.

![Tabby to BlackWhite](/assets/images/cat/tabby_to_bw.gif)
<div style="text-align:center"><i>Transforming a tabby cat face to a black and white cat face.</i></div>
![Opened to Closed](/assets/images/cat/open_to_close.gif)
<div style="text-align:center"><i>Transforming an open-eyed cat face to a closed-eyed cat face.</i></div>
![Left to Right](/assets/images/cat/left_to_right.gif)
<div style="text-align:center"><i>Transforming a left-facing cat face to a right-facing cat face.</i></div>

## Conclusion
This deep learning journey has led to the development of an impressive VAE capable of generating and transforming cat faces. The improved VAE's success in producing cat faces and executing precise transformations is a testament to its capabilities.

## Future Work
The journey doesn't end here. There are exciting avenues to explore in future work:
- **Real-Time Transformations:** Implementing real-time transformations to make the project more interactive.
- **Larger Dataset:** Training on a larger and more diverse dataset to enhance the model's ability to generate and transform cat faces.
- **User Interface:** Creating a user-friendly interface for users to upload cat images and apply transformations with ease.

## Acknowledgments
I would like to express my gratitude to the authors of "Deep Learning with Python, Second Edition" for their invaluable guidance and the Kaggle community for the cat-dataset.

## References
- [Deep Learning with Python, Second Edition][vae-tutorial]
- [Kaggle Cat Dataset][cat-dataset]

## Code
If you're interested in exploring the code behind this project, you can find the complete implementation on my [GitHub repository][github-vae]. The repository contains exploratory notebooks, final/cleaned notebooks will be added soon.

[github-vae]: https://github.com/HunBug/autoencoder/tree/main/workflow/VaeTutorial
[vae-tutorial]: https://github.com/fchollet/deep-learning-with-python-notebooks/blob/master/chapter12_part04_variational-autoencoders.ipynb
[cat-dataset]: https://www.kaggle.com/datasets/crawford/cat-dataset